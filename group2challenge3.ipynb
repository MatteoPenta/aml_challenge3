{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Example solution for tweet sentiment analysis\n\nThis is a baseline example to help you with the third challenge. It was originally developed by our Ph.D. student Jonas Wacker","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom tqdm.notebook import tqdm # progress bars\n\n# plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\n# general NLP preprocessing and basic tools\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# train/test split\nfrom sklearn.model_selection import train_test_split\n# basic machine learning models\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n# our evaluation metric for sentiment classification\nfrom sklearn.metrics import fbeta_score","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:20.373415Z","iopub.execute_input":"2023-06-07T13:59:20.374418Z","iopub.status.idle":"2023-06-07T13:59:20.383495Z","shell.execute_reply.started":"2023-06-07T13:59:20.374374Z","shell.execute_reply":"2023-06-07T13:59:20.382559Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# install HuggingFace's transformers library\n! pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:20.395531Z","iopub.execute_input":"2023-06-07T13:59:20.395876Z","iopub.status.idle":"2023-06-07T13:59:31.388344Z","shell.execute_reply.started":"2023-06-07T13:59:20.395851Z","shell.execute_reply":"2023-06-07T13:59:31.387195Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.390806Z","iopub.execute_input":"2023-06-07T13:59:31.391173Z","iopub.status.idle":"2023-06-07T13:59:31.401176Z","shell.execute_reply.started":"2023-06-07T13:59:31.391136Z","shell.execute_reply":"2023-06-07T13:59:31.399709Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"/kaggle/input/eurecom-aml-2023-challenge-3/sample_submission.csv\n/kaggle/input/eurecom-aml-2023-challenge-3/train.csv\n/kaggle/input/eurecom-aml-2023-challenge-3/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/eurecom-aml-2023-challenge-3/train.csv')\ntest_df = pd.read_csv('/kaggle/input/eurecom-aml-2023-challenge-3/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.402616Z","iopub.execute_input":"2023-06-07T13:59:31.402918Z","iopub.status.idle":"2023-06-07T13:59:31.481907Z","shell.execute_reply.started":"2023-06-07T13:59:31.402895Z","shell.execute_reply":"2023-06-07T13:59:31.480968Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Quick data inspection","metadata":{}},{"cell_type":"code","source":"len(train_df)+len(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.484392Z","iopub.execute_input":"2023-06-07T13:59:31.484766Z","iopub.status.idle":"2023-06-07T13:59:31.491684Z","shell.execute_reply.started":"2023-06-07T13:59:31.484734Z","shell.execute_reply":"2023-06-07T13:59:31.490594Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"27480"},"metadata":{}}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.493124Z","iopub.execute_input":"2023-06-07T13:59:31.493983Z","iopub.status.idle":"2023-06-07T13:59:31.506716Z","shell.execute_reply.started":"2023-06-07T13:59:31.493951Z","shell.execute_reply":"2023-06-07T13:59:31.505564Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  28ac06f416                        good luck with your auction   \n1  92098cf9a7  Hmm..You can`t judge a book by looking at its ...   \n2  7858ff28f2   Hello, yourself. Enjoy London. Watch out for ...   \n3  b0c9c67f32         We can`t even call you from belgium  sucks   \n4  7b36e9e7a5                                 not so good mood..   \n\n                                       selected_text sentiment  \n0                        good luck with your auction  positive  \n1  Hmm..You can`t judge a book by looking at its ...   neutral  \n2                                    They`re mental.  negative  \n3                                            m  suck  negative  \n4                                 not so good mood..  negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28ac06f416</td>\n      <td>good luck with your auction</td>\n      <td>good luck with your auction</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>92098cf9a7</td>\n      <td>Hmm..You can`t judge a book by looking at its ...</td>\n      <td>Hmm..You can`t judge a book by looking at its ...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7858ff28f2</td>\n      <td>Hello, yourself. Enjoy London. Watch out for ...</td>\n      <td>They`re mental.</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b0c9c67f32</td>\n      <td>We can`t even call you from belgium  sucks</td>\n      <td>m  suck</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7b36e9e7a5</td>\n      <td>not so good mood..</td>\n      <td>not so good mood..</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.507958Z","iopub.execute_input":"2023-06-07T13:59:31.508458Z","iopub.status.idle":"2023-06-07T13:59:31.520066Z","shell.execute_reply.started":"2023-06-07T13:59:31.508426Z","shell.execute_reply":"2023-06-07T13:59:31.519022Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  102f98e5e2                          Happy Mother`s Day hahaha   \n1  033b399113  Sorry for the triple twitter post, was having ...   \n2  c125e29be2           thats much better than the flu syndrome!   \n3  b91e2b0679                            Aww I have a tummy ache   \n4  1a46141274   hey chocolate chips is good.  i want a snack ...   \n\n                                       selected_text  \n0                                 Happy Mother`s Day  \n1  Sorry for the triple twitter post, was having ...  \n2                                  thats much better  \n3                                         tummy ache  \n4                                              good.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102f98e5e2</td>\n      <td>Happy Mother`s Day hahaha</td>\n      <td>Happy Mother`s Day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>033b399113</td>\n      <td>Sorry for the triple twitter post, was having ...</td>\n      <td>Sorry for the triple twitter post, was having ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c125e29be2</td>\n      <td>thats much better than the flu syndrome!</td>\n      <td>thats much better</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b91e2b0679</td>\n      <td>Aww I have a tummy ache</td>\n      <td>tummy ache</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1a46141274</td>\n      <td>hey chocolate chips is good.  i want a snack ...</td>\n      <td>good.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data exploration","metadata":{}},{"cell_type":"code","source":"# stuff","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.521588Z","iopub.execute_input":"2023-06-07T13:59:31.522131Z","iopub.status.idle":"2023-06-07T13:59:31.528480Z","shell.execute_reply.started":"2023-06-07T13:59:31.522101Z","shell.execute_reply":"2023-06-07T13:59:31.527478Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Data pre-processing","metadata":{}},{"cell_type":"code","source":"# we create a validation dataset from the training data\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.530102Z","iopub.execute_input":"2023-06-07T13:59:31.530426Z","iopub.status.idle":"2023-06-07T13:59:31.545476Z","shell.execute_reply.started":"2023-06-07T13:59:31.530397Z","shell.execute_reply":"2023-06-07T13:59:31.544438Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"We start off by converting the labels to numbers. This is a requirement for the submission and numerical inputs are generally more compatible with machine learning libraries.","metadata":{}},{"cell_type":"code","source":"target_conversion = {\n    'neutral': 0,\n    'positive': 1,\n    'negative': 2\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.547033Z","iopub.execute_input":"2023-06-07T13:59:31.548140Z","iopub.status.idle":"2023-06-07T13:59:31.552541Z","shell.execute_reply.started":"2023-06-07T13:59:31.548109Z","shell.execute_reply":"2023-06-07T13:59:31.551486Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_df['target'] = train_df['sentiment'].map(target_conversion)\nval_df['target'] = val_df['sentiment'].map(target_conversion)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.557138Z","iopub.execute_input":"2023-06-07T13:59:31.557502Z","iopub.status.idle":"2023-06-07T13:59:31.570089Z","shell.execute_reply.started":"2023-06-07T13:59:31.557394Z","shell.execute_reply":"2023-06-07T13:59:31.568894Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"##  Loading Tokenizer and Encoding our Data","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.572062Z","iopub.execute_input":"2023-06-07T13:59:31.572696Z","iopub.status.idle":"2023-06-07T13:59:31.579910Z","shell.execute_reply.started":"2023-06-07T13:59:31.572665Z","shell.execute_reply":"2023-06-07T13:59:31.579051Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\n    'bert-base-uncased',\n    do_lower_case=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.583028Z","iopub.execute_input":"2023-06-07T13:59:31.583290Z","iopub.status.idle":"2023-06-07T13:59:31.858859Z","shell.execute_reply.started":"2023-06-07T13:59:31.583257Z","shell.execute_reply":"2023-06-07T13:59:31.857931Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Encoding training and validation data","metadata":{}},{"cell_type":"code","source":"encoded_data_train = tokenizer.batch_encode_plus(\n    train_df.text.values,\n    add_special_tokens=True,\n    return_attention_mask=True,\n    pad_to_max_length=True,\n    max_length=256,\n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    val_df.text.values,\n    add_special_tokens=True,\n    return_attention_mask=True,\n    pad_to_max_length=True,\n    max_length=256,\n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(train_df.target.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(val_df.target.values)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:31.860568Z","iopub.execute_input":"2023-06-07T13:59:31.860926Z","iopub.status.idle":"2023-06-07T13:59:51.832217Z","shell.execute_reply.started":"2023-06-07T13:59:31.860893Z","shell.execute_reply":"2023-06-07T13:59:51.831236Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_train = TensorDataset(input_ids_train, \n                              attention_masks_train,\n                              labels_train)\n\ndataset_val = TensorDataset(input_ids_val, \n                            attention_masks_val,\n                           labels_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:51.833679Z","iopub.execute_input":"2023-06-07T13:59:51.834015Z","iopub.status.idle":"2023-06-07T13:59:51.842012Z","shell.execute_reply.started":"2023-06-07T13:59:51.833982Z","shell.execute_reply":"2023-06-07T13:59:51.841017Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"len(dataset_train)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:51.843484Z","iopub.execute_input":"2023-06-07T13:59:51.843832Z","iopub.status.idle":"2023-06-07T13:59:51.854247Z","shell.execute_reply.started":"2023-06-07T13:59:51.843802Z","shell.execute_reply":"2023-06-07T13:59:51.853265Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"22258"},"metadata":{}}]},{"cell_type":"code","source":"dataset_val.tensors","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:51.856016Z","iopub.execute_input":"2023-06-07T13:59:51.856807Z","iopub.status.idle":"2023-06-07T13:59:51.866694Z","shell.execute_reply.started":"2023-06-07T13:59:51.856773Z","shell.execute_reply":"2023-06-07T13:59:51.865646Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 101, 3232, 2420,  ...,    0,    0,    0],\n         [ 101, 2016, 2134,  ...,    0,    0,    0],\n         [ 101, 1030, 1035,  ...,    0,    0,    0],\n         ...,\n         [ 101, 1035, 2857,  ...,    0,    0,    0],\n         [ 101, 8840, 2140,  ...,    0,    0,    0],\n         [ 101, 2821, 1998,  ...,    0,    0,    0]]),\n tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]]),\n tensor([0, 0, 0,  ..., 1, 0, 2]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Setting up BERT Pretrained Model","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:51.868468Z","iopub.execute_input":"2023-06-07T13:59:51.868830Z","iopub.status.idle":"2023-06-07T13:59:51.874157Z","shell.execute_reply.started":"2023-06-07T13:59:51.868799Z","shell.execute_reply":"2023-06-07T13:59:51.873166Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\n                                      'bert-base-uncased', \n                                      num_labels = len(target_conversion),\n                                      output_attentions = False,\n                                      output_hidden_states = False\n                                     )","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:51.875800Z","iopub.execute_input":"2023-06-07T13:59:51.876208Z","iopub.status.idle":"2023-06-07T13:59:54.025627Z","shell.execute_reply.started":"2023-06-07T13:59:51.876112Z","shell.execute_reply":"2023-06-07T13:59:54.024741Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setting up RoBERTa Pretrained model","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-06-07T14:25:21.540465Z","iopub.execute_input":"2023-06-07T14:25:21.540836Z","iopub.status.idle":"2023-06-07T14:25:32.447263Z","shell.execute_reply.started":"2023-06-07T14:25:21.540807Z","shell.execute_reply":"2023-06-07T14:25:32.446354Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\n                                      'roberta-base', \n                                      num_labels = len(target_conversion),\n                                      output_attentions = False,\n                                      output_hidden_states = False\n                                     )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Data Loaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.027298Z","iopub.execute_input":"2023-06-07T13:59:54.027677Z","iopub.status.idle":"2023-06-07T13:59:54.032249Z","shell.execute_reply.started":"2023-06-07T13:59:54.027644Z","shell.execute_reply":"2023-06-07T13:59:54.031086Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"batch_size = 4\n\ndataloader_train = DataLoader(\n    dataset_train,\n    sampler=RandomSampler(dataset_train),\n    batch_size=batch_size\n)\n\ndataloader_val = DataLoader(\n    dataset_val,\n    sampler=RandomSampler(dataset_val),\n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.033901Z","iopub.execute_input":"2023-06-07T13:59:54.034276Z","iopub.status.idle":"2023-06-07T13:59:54.043769Z","shell.execute_reply.started":"2023-06-07T13:59:54.034242Z","shell.execute_reply":"2023-06-07T13:59:54.042900Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## Setting Up Optimizer and Scheduler","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.046630Z","iopub.execute_input":"2023-06-07T13:59:54.047005Z","iopub.status.idle":"2023-06-07T13:59:54.056405Z","shell.execute_reply.started":"2023-06-07T13:59:54.046974Z","shell.execute_reply":"2023-06-07T13:59:54.055560Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(\n    model.parameters(),\n    lr = 1e-5,\n    eps = 1e-8\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.057880Z","iopub.execute_input":"2023-06-07T13:59:54.058433Z","iopub.status.idle":"2023-06-07T13:59:54.069822Z","shell.execute_reply.started":"2023-06-07T13:59:54.058403Z","shell.execute_reply":"2023-06-07T13:59:54.068857Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 10\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps = len(dataloader_train)*epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.071144Z","iopub.execute_input":"2023-06-07T13:59:54.071743Z","iopub.status.idle":"2023-06-07T13:59:54.088745Z","shell.execute_reply.started":"2023-06-07T13:59:54.071711Z","shell.execute_reply":"2023-06-07T13:59:54.087923Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Defining our Performance Metrics\n\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.090185Z","iopub.execute_input":"2023-06-07T13:59:54.090745Z","iopub.status.idle":"2023-06-07T13:59:54.094704Z","shell.execute_reply.started":"2023-06-07T13:59:54.090714Z","shell.execute_reply":"2023-06-07T13:59:54.093794Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average = 'macro')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.095979Z","iopub.execute_input":"2023-06-07T13:59:54.096554Z","iopub.status.idle":"2023-06-07T13:59:54.105197Z","shell.execute_reply.started":"2023-06-07T13:59:54.096495Z","shell.execute_reply":"2023-06-07T13:59:54.104370Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.106555Z","iopub.execute_input":"2023-06-07T13:59:54.107104Z","iopub.status.idle":"2023-06-07T13:59:54.115382Z","shell.execute_reply.started":"2023-06-07T13:59:54.107074Z","shell.execute_reply":"2023-06-07T13:59:54.114551Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"## Creating our Training Loop","metadata":{}},{"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.116763Z","iopub.execute_input":"2023-06-07T13:59:54.117383Z","iopub.status.idle":"2023-06-07T13:59:54.125920Z","shell.execute_reply.started":"2023-06-07T13:59:54.117351Z","shell.execute_reply":"2023-06-07T13:59:54.124990Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:54.132242Z","iopub.execute_input":"2023-06-07T13:59:54.132550Z","iopub.status.idle":"2023-06-07T13:59:58.479408Z","shell.execute_reply.started":"2023-06-07T13:59:54.132473Z","shell.execute_reply":"2023-06-07T13:59:58.478329Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(dataloader_val):\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in tqdm(dataloader_val):\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2023-06-07T13:59:58.481003Z","iopub.execute_input":"2023-06-07T13:59:58.481332Z","iopub.status.idle":"2023-06-07T13:59:58.489929Z","shell.execute_reply.started":"2023-06-07T13:59:58.481300Z","shell.execute_reply":"2023-06-07T13:59:58.488713Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{}},{"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    model.train()\n    loss_train_total = 0\n    \n    progress_bar = tqdm(dataloader_train, \n                        desc='Epoch {:1d}'.format(epoch), \n                        leave=False, \n                        disable=False)\n    \n    for batch in progress_bar:\n        model.zero_grad()\n        batch = tuple(b.to(device) for b in batch)\n        inputs = {\n            'input_ids': batch[0],\n            'attention_mask': batch[1],\n            'labels': batch[2]\n        }\n        \n        outputs = model(**inputs)\n        loss = outputs[0]\n        loss_train_total +=loss.item()\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n    \n    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n    \n    tqdm.write('\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)\n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_val)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (macro): {val_f1}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T14:00:09.824132Z","iopub.execute_input":"2023-06-07T14:00:09.824487Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf2b894952441f798d028b6061cd58e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/5565 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch {epoch}\nTraining loss: 0.661934728919874\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc483d718f254e70a44a9c7b70b1c614"}},"metadata":{}},{"name":"stdout","text":"Validation loss: 0.6093265222242246\nF1 Score (macro): 0.7950058935126392\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/5565 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a4aa2119bf4a0b9f53740f8719e8fe"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluating our Model","metadata":{}},{"cell_type":"code","source":"accuracy_per_class(predictions, true_vals)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a simple classifier\n\nWe are training a naive Bayes classifier on the Bag-of-Words features of the training data:\n\nhttps://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n\nIt is already built into the sklearn library:\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n\nKeep in mind that not only storing the features is challenging but also processing them. A simple SVM may be quite slow on such high-dimensional features. Naive Bayes works well with Bag-of-Words.\n\n","metadata":{}},{"cell_type":"code","source":"%%time\nclf = MultinomialNB().fit(X_train_counts, train_df['target'])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.15871Z","iopub.execute_input":"2023-05-22T15:45:52.159005Z","iopub.status.idle":"2023-05-22T15:45:52.186597Z","shell.execute_reply.started":"2023-05-22T15:45:52.158978Z","shell.execute_reply":"2023-05-22T15:45:52.18563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_predictions_nb = clf.predict(X_val_counts)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.187556Z","iopub.execute_input":"2023-05-22T15:45:52.18788Z","iopub.status.idle":"2023-05-22T15:45:52.194407Z","shell.execute_reply.started":"2023-05-22T15:45:52.187849Z","shell.execute_reply":"2023-05-22T15:45:52.193497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (val_predictions_nb == val_df['target'].values).mean()\nprint('The accuracy of our multinomial Naive Bayes classifier is: {:.2f}%'.format(accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.19541Z","iopub.execute_input":"2023-05-22T15:45:52.195756Z","iopub.status.idle":"2023-05-22T15:45:52.205014Z","shell.execute_reply.started":"2023-05-22T15:45:52.195726Z","shell.execute_reply":"2023-05-22T15:45:52.204063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fbeta = fbeta_score(val_df['target'].values, val_predictions_nb, average='macro', beta=1.0)\nprint('The fbeta score is:', fbeta)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.206336Z","iopub.execute_input":"2023-05-22T15:45:52.206691Z","iopub.status.idle":"2023-05-22T15:45:52.218349Z","shell.execute_reply.started":"2023-05-22T15:45:52.206649Z","shell.execute_reply":"2023-05-22T15:45:52.217572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a submission\n\nX_train_counts = count_vect.fit_transform(list(train_df['text'].values) + list(val_df['text'].values))\nX_test_counts = count_vect.transform(list(test_df['text'].values))\n\nclf = MultinomialNB().fit(X_train_counts, np.hstack([train_df['target'].values, val_df['target'].values]))\ntest_predictions_nb = clf.predict(X_test_counts)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb\nsubmission_df.to_csv('TA_baseline_NB.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.219509Z","iopub.execute_input":"2023-05-22T15:45:52.21981Z","iopub.status.idle":"2023-05-22T15:45:52.900508Z","shell.execute_reply.started":"2023-05-22T15:45:52.219784Z","shell.execute_reply":"2023-05-22T15:45:52.899434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How good is this score?\n\nEarly approaches in NLP used rule-based classifiers for sentiment analysis. A popular baseline is VADER which was published in 2014:\n\nhttps://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8109\n\nVADER does not use any machine learning but is purely handcrafted by humans. It uses text preprocessing and lexica to determine the sentiment of a text.","metadata":{}},{"cell_type":"code","source":"nltk.download('vader_lexicon')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.902027Z","iopub.execute_input":"2023-05-22T15:45:52.902384Z","iopub.status.idle":"2023-05-22T15:45:52.990586Z","shell.execute_reply.started":"2023-05-22T15:45:52.902353Z","shell.execute_reply":"2023-05-22T15:45:52.9895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sid = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:52.992066Z","iopub.execute_input":"2023-05-22T15:45:52.992458Z","iopub.status.idle":"2023-05-22T15:45:53.01326Z","shell.execute_reply.started":"2023-05-22T15:45:52.992415Z","shell.execute_reply":"2023-05-22T15:45:53.012131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We show a few prediction examples:\nfor doc in val_df['text'].iloc[:5].values:\n    print(doc)\n    print(sid.polarity_scores(doc))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.017959Z","iopub.execute_input":"2023-05-22T15:45:53.018297Z","iopub.status.idle":"2023-05-22T15:45:53.026221Z","shell.execute_reply.started":"2023-05-22T15:45:53.01826Z","shell.execute_reply":"2023-05-22T15:45:53.025182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vader_predict(x):\n    prediction = sid.polarity_scores(x)\n    prediction_list = [\n        (1, prediction['pos']),\n        (-1, prediction['neg']),\n        (0, prediction['neu'])\n    ]\n    label = sorted(prediction_list, key=lambda x: x[1], reverse=True)[0][0]\n    return label","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.027414Z","iopub.execute_input":"2023-05-22T15:45:53.02786Z","iopub.status.idle":"2023-05-22T15:45:53.037369Z","shell.execute_reply.started":"2023-05-22T15:45:53.027829Z","shell.execute_reply":"2023-05-22T15:45:53.036212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_vader = val_df['text'].apply(vader_predict)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.038917Z","iopub.execute_input":"2023-05-22T15:45:53.039336Z","iopub.status.idle":"2023-05-22T15:45:53.64547Z","shell.execute_reply.started":"2023-05-22T15:45:53.039295Z","shell.execute_reply":"2023-05-22T15:45:53.644335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (predictions_vader == val_df['target'].values).mean()\nprint('The accuracy of VADER is: {:.2f}%'.format(accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.646941Z","iopub.execute_input":"2023-05-22T15:45:53.648025Z","iopub.status.idle":"2023-05-22T15:45:53.654847Z","shell.execute_reply.started":"2023-05-22T15:45:53.647981Z","shell.execute_reply":"2023-05-22T15:45:53.653939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fbeta = fbeta_score(val_df['target'].values, predictions_vader, average='macro', beta=1.0)\nprint('The fbeta score is:', fbeta)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.655749Z","iopub.execute_input":"2023-05-22T15:45:53.656034Z","iopub.status.idle":"2023-05-22T15:45:53.676344Z","shell.execute_reply.started":"2023-05-22T15:45:53.656007Z","shell.execute_reply":"2023-05-22T15:45:53.675276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"VADER performs worse! That is a good sign that our classifier learned useful generalizations from the training data (better than standard handcrafted rules).","metadata":{}},{"cell_type":"markdown","source":"## Where to go from here?\n\nWe can improve our Machine Learning pipeline on multiple aspects:\n\n### Data analysis:\nHow is the data distributed? Can we analyze our data to find patterns associated with the classes? Which kinds of words are useful, which aren't?\n\n### Feature extraction:\nCan we make our Bag-of-Words representation more compact or richer? There are many things you could try to implement. Here are some buzzwords: tokenization, stop words removal, lemmatization, n-gram extraction, ...\nA useful Python library to address these issues is: NLTK (https://www.nltk.org/)\nThe sklearn CountVectorizer we used can be combined with NLTK preprocessing: https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes\nIs there also a dense (as opposed to sparse) representation of documents (tweets in our case)? Buzzwords: word2vec, gloVe\nThe state-of-the-art: ... are neural network language models, so-called Transformers. There are pretrained models available. If you feel comfortable with neural networks, fine-tuning and GPUs, have a look here: https://huggingface.co/transformers/\n\nIn general, we also recommend spaCy as a convenient Python library that covers most of the above features at once and may be a great resource to start with: https://spacy.io/\n\n### Model selection:\nThe model of choice highly depends on the previously extracted features. Depending on whether you obtain a sparse or dense feature representation, you have to choose an appropriate model!\n\n### Model evaluation:\nMake sure to select potential model hyperparameters using cross-validation or similar. Our evaluation metric of choice is the F1-score:\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score\n\nWe choose beta=1 and average=macro\n\n### Extension idea 1:\nApart from classifying the sentiment of tweets, we can also try to determine which words are the reason for the classifier to determine the classification. Ground-truth labels for these words are contained in our training data. The evaluation will not take place on the Kaggle platform. You need to do it yourself. Use the Jaccard coefficient to evaluate the overlap between the selected words and the ground truth:\n\nhttps://scikit-learn.org/stable/modules/model_evaluation.html#jaccard-similarity-coefficient-score","metadata":{}},{"cell_type":"code","source":"# selected_text shows the words selected from text to lead to the classification stored in sentiment\ntrain_df[['text', 'selected_text', 'sentiment']].iloc[:5]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:53.678014Z","iopub.execute_input":"2023-05-22T15:45:53.678802Z","iopub.status.idle":"2023-05-22T15:45:53.693856Z","shell.execute_reply.started":"2023-05-22T15:45:53.678756Z","shell.execute_reply":"2023-05-22T15:45:53.692622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extension idea 2:\n\nYou may want to give it a try to Kaggle's brand new feature called models!","metadata":{}}]}